{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDCKSQ7Gmsvl"
      },
      "source": [
        "### **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout"
      ],
      "metadata": {
        "id": "LZa1qcz2qCvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilcj0Joomsvu"
      },
      "outputs": [],
      "source": [
        "class StockPricePredictor:\n",
        "    def __init__(self, csv_file, time_step=2):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.time_step = time_step\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        # Convert 'Date' to datetime and extract year, month, day\n",
        "        self.df['Date'] = self.df['Date'].astype(str).str.split(' ').str[0]\n",
        "        self.df['Date'] = pd.to_datetime(self.df['Date'], errors='coerce')\n",
        "        self.df['year'] = self.df['Date'].dt.year\n",
        "        self.df['month'] = self.df['Date'].dt.month\n",
        "        self.df['day'] = self.df['Date'].dt.day\n",
        "        self.df.drop(columns=['Date', 'Company'], inplace=True)\n",
        "\n",
        "        # Split features and target\n",
        "        X = self.df[['Open', 'High', 'Low', 'Volume']]\n",
        "        Y = self.df['Close'].values\n",
        "\n",
        "        # Scale the features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        return X_scaled, Y\n",
        "\n",
        "    def create_sequences(self, data, target):\n",
        "        X_seq, y_seq = [], []\n",
        "        for i in range(len(data) - self.time_step):\n",
        "            X_seq.append(data[i:(i + self.time_step)])\n",
        "            y_seq.append(target[i + self.time_step])\n",
        "        return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "    def build_model(self, input_shape):\n",
        "        self.model = Sequential()\n",
        "        self.model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
        "        self.model.add(Dropout(0.3))\n",
        "        self.model.add(LSTM(100, return_sequences=False))\n",
        "        self.model.add(Dropout(0.3))\n",
        "        self.model.add(Dense(50))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "                           loss='mean_squared_error')\n",
        "        self.model.summary()\n",
        "\n",
        "    def train_model(self, X_seq, y_seq):\n",
        "        # Use only the first 20% of the data for faster training\n",
        "        X_train = X_seq[:int(0.2 * len(X_seq))]\n",
        "        y_train = y_seq[:int(0.2 * len(y_seq))]\n",
        "\n",
        "        # Create a TensorFlow dataset\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=512).batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(train_dataset, epochs=10)\n",
        "\n",
        "        # Plot the loss\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.show()\n",
        "\n",
        "    def make_prediction(self, input_data):\n",
        "        # Reshape the input to match model's expected shape\n",
        "        reshaped_input = np.tile(input_data, (self.time_step, 1))\n",
        "        reshaped_input = reshaped_input.reshape((1, self.time_step, reshaped_input.shape[1]))\n",
        "\n",
        "        # Make a prediction\n",
        "        predictions = self.model.predict(reshaped_input)\n",
        "        return predictions\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the class\n",
        "    predictor = StockPricePredictor('stock_details_5_years.csv')\n",
        "\n",
        "    # Preprocess the data\n",
        "    X_scaled, Y = predictor.preprocess_data()\n",
        "\n",
        "    # Create sequences\n",
        "    X_seq, y_seq = predictor.create_sequences(X_scaled, Y)\n",
        "\n",
        "    # Build and train the model\n",
        "    input_shape = (X_seq.shape[1], X_seq.shape[2])\n",
        "    predictor.build_model(input_shape)\n",
        "    predictor.train_model(X_seq, y_seq)\n",
        "\n",
        "    # Example prediction\n",
        "    input_data = np.array([[54.176498, 55.007500, 54.099998, 31004000]])  # Shape is (1, 4)\n",
        "    prediction = predictor.make_prediction(input_data)\n",
        "    print(\"Prediction:\", prediction)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "umer_env",
      "language": "python",
      "name": "umer_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}